{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#Q 1. (a)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataset (features and labels)\n",
    "X = np.array([[-1, -1], [1, 0], [-1, 1.5]])\n",
    "y = np.array([1, -1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 1: Start with x^(1)\n",
    "theta = np.zeros(2)  # Initialize weight vector as [0,0]\n",
    "mistakes_x1 = 0  # Counter for mistakes (updates)\n",
    "progression_x1 = [theta.tolist()]  # Track weight vector progression\n",
    "converged = False\n",
    "\n",
    "# Iterate until convergence (no mistakes in one full cycle)\n",
    "while not converged:\n",
    "    converged = True  # Assume convergence unless a mistake is found\n",
    "    for i in range(len(X)):  # Go through each data point in order\n",
    "        if np.sign(np.dot(theta, X[i])) != y[i]:  # If misclassified\n",
    "            theta += y[i] * X[i]  # Update weights using perceptron rule\n",
    "            mistakes_x1 += 1  # Count the update as a mistake\n",
    "            progression_x1.append(theta.tolist())  # Track new weight vector\n",
    "            converged = False  # Since a mistake was made, continue looping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 2: Start with x^(2)\n",
    "theta = np.zeros(2)  # Reset weight vector to [0,0]\n",
    "mistakes_x2 = 0  # Counter for mistakes (updates)\n",
    "progression_x2 = [theta.tolist()]  # Track weight vector progression\n",
    "converged = False\n",
    "\n",
    "# Iterate until convergence (no mistakes in one full cycle)\n",
    "while not converged:\n",
    "    converged = True  # Assume convergence unless a mistake is found\n",
    "    for i in range(1, len(X) + 1):  # Start at index 1 and cycle through\n",
    "        index = i % len(X)  # Cycling through data\n",
    "        if np.sign(np.dot(theta, X[index])) != y[index]:  # If misclassified\n",
    "            theta += y[index] * X[index]  # Update weights\n",
    "            mistakes_x2 += 1  # Count the update as a mistake\n",
    "            progression_x2.append(theta.tolist())  # Track new weight vector\n",
    "            converged = False  # Since a mistake was made, continue looping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Starting Point  Mistakes                              Progression\n",
      "0          x^(1)         2  [[0.0, 0.0], [-1.0, -1.0], [-2.0, 0.5]]\n",
      "1          x^(2)         1                [[0.0, 0.0], [-1.0, 0.0]]\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame to display results\n",
    "df_results = pd.DataFrame({\n",
    "    \"Starting Point\": [\"x^(1)\", \"x^(2)\"],\n",
    "    \"Mistakes\": [mistakes_x1, mistakes_x2],\n",
    "    \"Progression\": [progression_x1, progression_x2]\n",
    "})\n",
    "\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#Q 1. (c)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the dataset with new x^(3) value\n",
    "X_new = np.array([[-1, -1], [1, 0], [-1, 10]])\n",
    "y_new = np.array([1, -1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Start with x^(1)\n",
    "theta = np.zeros(2)  # Initialize weight vector as [0,0]\n",
    "mistakes_x1_new = 0  # Counter for mistakes (updates)\n",
    "progression_x1_new = [theta.tolist()]  # Track weight vector progression\n",
    "converged = False\n",
    "\n",
    "# Iterate until convergence (no mistakes in one full cycle)\n",
    "while not converged:\n",
    "    converged = True  # Assume convergence unless a mistake is found\n",
    "    for i in range(len(X_new)):  # Go through each data point in order\n",
    "        if np.sign(np.dot(theta, X_new[i])) != y_new[i]:  # If misclassified\n",
    "            theta += y_new[i] * X_new[i]  # Update weights using perceptron rule\n",
    "            mistakes_x1_new += 1  # Count the update as a mistake\n",
    "            progression_x1_new.append(theta.tolist())  # Track new weight vector\n",
    "            converged = False  # Since a mistake was made, continue looping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 2: Start with x^(2)\n",
    "theta = np.zeros(2)  # Reset weight vector to [0,0]\n",
    "mistakes_x2_new = 0  # Counter for mistakes (updates)\n",
    "progression_x2_new = [theta.tolist()]  # Track weight vector progression\n",
    "converged = False\n",
    "\n",
    "# Iterate until convergence (no mistakes in one full cycle)\n",
    "while not converged:\n",
    "    converged = True  # Assume convergence unless a mistake is found\n",
    "    for i in range(1, len(X) + 1):  # Start at index 1 and cycle through\n",
    "        index = i % len(X)  # Cycling through data\n",
    "        if np.sign(np.dot(theta, X[index])) != y[index]:  # If misclassified\n",
    "            theta += y[index] * X[index]  # Update weights\n",
    "            mistakes_x2_new += 1  # Count the update as a mistake\n",
    "            progression_x2_new.append(theta.tolist())  # Track new weight vector\n",
    "            converged = False  # Since a mistake was made, continue looping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Starting Point  Mistakes                                        Progression\n",
      "0          x^(1)         6  [[0.0, 0.0], [-1.0, -1.0], [-2.0, 9.0], [-3.0,...\n",
      "1          x^(2)         1                          [[0.0, 0.0], [-1.0, 0.0]] \n",
      "\n",
      "[0.0, 0.0]\n",
      "[-1.0, -1.0]\n",
      "[-2.0, 9.0]\n",
      "[-3.0, 8.0]\n",
      "[-4.0, 7.0]\n",
      "[-5.0, 6.0]\n",
      "[-6.0, 5.0] \n",
      "\n",
      "[0.0, 0.0]\n",
      "[-1.0, 0.0] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame to display results\n",
    "df_results = pd.DataFrame({\n",
    "    \"Starting Point\": [\"x^(1)\", \"x^(2)\"],\n",
    "    \"Mistakes\": [mistakes_x1_new, mistakes_x2_new],\n",
    "    \"Progression\": [progression_x1_new, progression_x2_new]\n",
    "})\n",
    "\n",
    "print(df_results, \"\\n\")\n",
    "print(\"\\n\".join(map(str, progression_x1_new)), \"\\n\")\n",
    "print(\"\\n\".join(map(str, progression_x2_new)), \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mitcourse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
